{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import konlpy\n",
    "import pickle\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from konlpy.utils import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "os.chdir('/root/nlp/RecipeBot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 전처리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(filename):\n",
    "    with codecs.open(filename,'r',encoding='utf8') as f:\n",
    "        data = [line for line in f.read().splitlines() if line != '']\n",
    "      #  data = data[1:]   # header 제외\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp = read_data('data/[Leopard-Raws] Shokugeki no Souma - 24 END (TBS 1280x720 x264 AAC).KRCC.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "name_dict = ['소마', '유키히라','나키리', '에리나', '타도코로', '메구미',\n",
    "            '타쿠미', '알디니', '나키리', '에리스', '토오츠키']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter1 = re.compile(r'<font.')\n",
    "filter2 = re.compile(r'by 천상.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pre_chat = []\n",
    "for sen in temp:\n",
    "    if ('<' not in sen) & (filter2.match(sen) == None):\n",
    "        pre_chat.append(sen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for sen2 in pre_chat:\n",
    "    if sen2 == '다시 태어나':\n",
    "        songIndex = pre_chat.index(sen2)\n",
    "        \n",
    "for x in range(songIndex,songIndex+17):\n",
    "    pre_chat[x] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pre_chat = [xx for xx in pre_chat if xx != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[﻿[유키히라 소마, 초등학교 6학년],\n",
      " 아버지!,\n",
      " [유키히라 소마, 초등학교 6학년],\n",
      " 난 말이야,\n",
      " [유키히라 소마, 초등학교 6학년],\n",
      " 아버지를 이길 요리사가 되겠어,\n",
      " [유키히라 죠이치로, 유키히라 점주],\n",
      " 아, 그러냐?,\n",
      " [유키히라 죠이치로, 유키히라 점주],\n",
      " 뭐, 열심히 해봐라,\n",
      " 그럼 곧바로,\n",
      " 요리 승부야!,\n",
      " 그 이후로 490전인가,\n",
      " 잘 들어라, 소마,\n",
      " 다음에 내게 질 때까지,\n",
      " 아무한테도 지지 마라,\n",
      " 역시 내 쪽이 맛없잖아,\n",
      " 소마,\n",
      " 비가 그친 하늘을 기다리는,\n",
      " 이 고요함을,\n",
      " 갈라버리고,\n",
      " 나아가기 시작한 나날 속에,\n",
      " 특별했던 사람이 하늘에 떠오르겠지,\n",
      " 미소 지을 거야,\n",
      " 당신을 지키는 건,\n",
      " 그런 사람과 쌓아온 추억들이겠지,\n",
      " 이 조그마한 손으로,\n",
      " 미래를 꽉꽉꽈악,\n",
      " 잡아낼 거야,\n",
      " 비가 그친 하늘을 봐봐,\n",
      " 무지개가 걸릴 거야,\n",
      " 그런 날이 오겠지,\n",
      " 지금 무릎을 꿇은 당신도 그래,\n",
      " 몇 번이라도 다시 일어날 거야,\n",
      " 타도코로 메구미 선수,\n",
      " 88점!,\n",
      " 4위!,\n",
      " 예선 돌파!,\n",
      " 3위는 90점,\n",
      " 타쿠미 알디니 선수!,\n",
      " 2위는 92점,\n",
      " 아라토 히사코 선수가 랭크인!,\n",
      " 향기만으로도 행복해,\n",
      " 먹고 싶다…!,\n",
      " 하야마 군,\n",
      " 난에 루를 묻혀,\n",
      " 넣는다!,\n",
      " 형언할 수 없어…,\n",
      " 파이로 감싼 수프,\n",
      " 프랑스 요리계를 대표하는 셰프,\n",
      " 폴 보퀴즈 씨가 만든 기법이다,\n",
      " 그는 이걸 일본 요리의,\n",
      " 밥그릇에서 착안했다고 하지,\n",
      " 요리의 향기는 파이 내부에 응축되고,\n",
      " 뚜껑을 뚫은 순간,\n",
      " 단숨에 풀려나 작렬한다,\n",
      " 향이라는 하야마의 무기,\n",
      " 그 최대 위력을,\n",
      " 심사위원에게 직격시켰어,\n",
      " 스파이스는 펜넬에 레몬그라스,\n",
      " 그리고 시나몬,\n",
      " 아니, 그걸 조율한 무언가가 있어,\n",
      " 이 강한 향의 중심은 뭐냐!,\n",
      " 홀리바질!,\n",
      " 그것도 생으로 썼어!,\n",
      " 홀리바질?,\n",
      " 남아시아 주변에서,\n",
      " 신성시하는 스파이스다,\n",
      " 그걸 맡으면 온몸에,\n",
      " 감미로운 감각이 흐르지,\n",
      " 인도의 전통적인 의학 체계,\n",
      " 아유르베다에서는 신비의,\n",
      " 묘약으로 자리 잡고 있지,\n",
      " 하지만 일본에서는,\n",
      " 양질의 생 홀리바질은,\n",
      " 거의 유통되지 않을 텐데!,\n",
      " 그렇지,\n",
      " 우리 시오미 세미나에서,\n",
      " 1년 내내 키우고 있어서,\n",
      " 뭐?!,\n",
      " 재배법은 기업 비밀,\n",
      " 시오미…,\n",
      " 스파이스의 권위자인,\n",
      " 시오미 준 교수 말이지!,\n",
      " [시오미 준(34),\n",
      " 스파이스의 권위자],\n",
      " 분명히 포로가 될 것 같은,\n",
      " 강렬한 향기야,\n",
      " 하지만 핵심은,\n",
      " 그것뿐만이 아니야,\n",
      " 입맛을 끌어당기는 건…,\n",
      " 요구르트구나!,\n",
      " 정답이다, 유키히라,\n",
      " 자칫 잘못하면 다른 스파이스를,\n",
      " 망칠 수 있는 홀리바질의 강한 개성,\n",
      " 요구르트는 그걸 부드럽게 만들거든,\n",
      " [롤랑 샤페르, 토오츠키,\n",
      " 프랑스 요리 부문 주임],\n",
      " 게다가 스파이스에 포함된,\n",
      " 커큐민에는 간장의 해독,\n",
      " 작용을 돕는 효과가 있지,\n",
      " 유산균,\n",
      " 즉, 요구르트와 함께 섭취하면,\n",
      " 보다 효율적으로 흡수되지,\n",
      " 영양까지 고려하다니!,\n",
      " 과연 하야마 군이야!,\n",
      " 대단해!,\n",
      " 홀리바질을 다뤄내는 요리사가,\n",
      " 이 나라에 있을 줄이야,\n",
      " 하야마 군~,\n",
      " 너, 내 것이 되지 않을래?,\n",
      " 연봉은 얼마가 좋니?,\n",
      " 1억?,\n",
      " 2억?,\n",
      " 네가 원하는 금액을…,\n",
      " 난 준을 위해 싸운다,\n",
      " 그것뿐이니까,\n",
      " 멋진 남자네,\n",
      " 더욱 갖고 싶어진다…,\n",
      " 한 입 머금을 때마다,\n",
      " 얼얼한 감칠맛이 뇌수를 관통한다!,\n",
      " 이런 샤프한 맛은,\n",
      " 여태껏 만나본 적이 없어!,\n",
      " 이 요리는 하나의 완성형,\n",
      " 현대 카레가 도달한 궁극점!,\n",
      " 그, 그럼 심사위원 여러분,\n",
      " 채점을 부탁드립니다,\n",
      " 얘들아!,\n",
      " B블록은 어떻게 됐어?,\n",
      " 그건 나중에 얘기할게,\n",
      " 이쪽은 어때?,\n",
      " 유키히라는?!,\n",
      " 유키히라는 몇 위지?!,\n",
      " 진정해, 형,\n",
      " 아직 채점 전인 모양이야,\n",
      " 하야마 선수의 득점은…,\n",
      " 나왔습니다~!,\n",
      " 하야마 선수, 94점으로,\n",
      " 1위에 올라섰습니다!,\n",
      " [하야마 아키라, 1st 94점],\n",
      " 하야마 군~!,\n",
      " 2위라,\n",
      " 아가씨가 성내시겠네,\n",
      " 뭐, 본선에서 노력하면 되겠지,\n",
      " [미토 이쿠미, 5th 86점, 낙선],\n",
      " 떨어졌나,\n",
      " 니쿠미!,\n",
      " 넌 정말 잘했어!,\n",
      " 잘했다아아아아아아!,\n",
      " 료코 짱…,\n",
      " 어이, 저기 봐,\n",
      " 20점 만점이 두 명이나 돼!,\n",
      " 하야마 아키라,\n",
      " 엄청나다,\n",
      " 나키리 아리스가 도달하지,\n",
      " 못했던 20점 만점인가,\n",
      " 정말 압권이네,\n",
      " 잇시키 선배!,\n",
      " 왜 여기에…,\n",
      " B블록 심사는요?,\n",
      " 사후처리는 맡기고 왔어,\n",
      " 야아, 이쪽도 격전이었구나,\n",
      " 잠깐만요!,\n",
      " 이 방은 관계자 외 출입…,\n",
      " 진정해, 진정,\n",
      " 사감 자격으로 부탁해,\n",
      " 그런 자격 없어요!,\n",
      " 너도 소마가 신경 쓰여서,\n",
      " A회장에 있는 거지?,\n",
      " 네?!,\n",
      " 그럴 리가…!,\n",
      " 자, 흥분이 사그라지지 않는 중에,\n",
      " 유키히라 선수의 등장입니다,\n",
      " 서빙을 부탁합니다,\n",
      " 소마 군,\n",
      " 대체 어떤 요리를…,\n",
      " 자~,\n",
      " 이건 네 몫이다,\n",
      " 그 표정은 뭐지?,\n",
      " 불과 한 달 전만 해도,\n",
      " 기본적인 스파이스인,\n",
      " 커리팟타도 모르던 녀석이,\n",
      " 내 카레를 입에 대고도,\n",
      " 어떻게 웃을 수 있지?,\n",
      " 야아~,\n",
      " 역시 내 아이디어는,\n",
      " 나쁘지 않은 것 같아서,\n",
      " 이건?!,\n",
      " 오믈렛?,\n",
      " 편입생은 리소토를 만들지 않았나?,\n",
      " 잡숴봐,\n",
      " 향기 폭탄,\n",
      " 2탄째!,\n",
      " 갈라진 오믈렛 안에 리소토가!,\n",
      " 갇혀있던 향기가,\n",
      " 폭발적으로 퍼진다!,\n",
      " 하야마의 요리에 이어,\n",
      " 향기의 폭탄이 직격?!,\n",
      " 나랑 같은 발상을…,\n",
      " 그런 모양이네,\n",
      " 여기까진…,\n",
      " 뜨거우니 조심하라고,\n",
      " 유키히라 특제,\n",
      " 카레 리소토 오므라이스,\n",
      " 계란에 갇혀있던 쌀이,\n",
      " 번들번들 윤이 나는 게,\n",
      " 최고급 소스를 끼얹은 덮밥 같아,\n",
      " 대단해,\n",
      " 어쩜 이렇게 부드러운 향기가…,\n",
      " 절로 얼굴이 풀어져!,\n",
      " 기대치는 하야마 군의 카레 못지않군,\n",
      " 그럼…,\n",
      " 강렬해!,\n",
      " 노도와 같은 맛의 타격!,\n",
      " 좋아!,\n",
      " 닭 뼈와 쇠심줄로 우린,\n",
      " 농후한 브이용,\n",
      " 버터로 볶은 다진 쇠고기와,\n",
      " 양파의 감칠맛이 밥에 배어…,\n",
      " 리소토의 걸쭉함이,\n",
      " 촉촉하게 부친 계란과 혼연일체를!,\n",
      " 거의 다리가 풀리기 직전이야!,\n",
      " 아무래도 결정타는 이 소스네,\n",
      " 굴소스를 베이스로,\n",
      " 벌꿀로 악센트를…,\n",
      " 부드러운 신맛이 농후해,\n",
      " 이 소스와 리소토로 2단계로,\n",
      " 풍미가 형성돼 있어!,\n",
      " 그렇구나,\n",
      " 하야마 군의 카레는,\n",
      " 무취에서 폭발했지만,\n",
      " 이건 이른바 향의 유폭,\n",
      " 안팎의 향이 단속적으로,\n",
      " 뒤섞여 유혹해온다!,\n",
      " 하지만 이 깊이는 그것만이 아니야,\n",
      " 향기로움과 약간의 떫은맛은,\n",
      " 쿠민과 카르다몸,\n",
      " 혀를 자극하는 클로브,\n",
      " 단편적인 향은 맡을 수 있지만,\n",
      " 표면적인 것에 불과해,\n",
      " 스파이스와 깊게 엮인 이 감칠맛은…,\n",
      " 알았다,\n",
      " 망고!,\n",
      " 망고 차트니!,\n",
      " 망고 차트니라고?!,\n",
      " 고작 그걸로 이렇게,\n",
      " 깊은 풍미가 생겨난다고?!,\n",
      " 차트니란 건 그거지?,\n",
      " 페이스트 상태의…,\n",
      " 그래,\n",
      " 스파이스를 과일이나,\n",
      " 채소와 함께 으깨거나,\n",
      " 졸여서 만드는 조미료야,\n",
      " 아시아 각지에서 조합에 따라,\n",
      " 달콤한 것이나 매운 것,\n",
      " 민트를 사용한 것 등으로,\n",
      " 다양한 종류가 존재하죠,\n",
      " 자가제 블렌딩 망고 차트니,\n",
      " 밥을 졸일 때 이걸 함께 넣었지,\n",
      " 망고가 주축이 되어,\n",
      " 스파이스 간의 고유한 맛을 합쳐,\n",
      " 요리에 한층 더 깊은,\n",
      " 감칠맛을 끌어내지,\n",
      " 말하자면 스파이스의 응용기술,\n",
      " 본고장인 인도에선,\n",
      " 어디까지나 곁들임,\n",
      " 양념 같은 취급이지,\n",
      " 카레 자체에 차트니를 넣는 건,\n",
      " 일본의 독자적인 수법이야,\n",
      " 호오~,\n",
      " 그렇구나,\n",
      " 본고장 쪽에서 보자면,\n",
      " 파격적인 조리법,\n",
      " 하지만 그로 인해,\n",
      " 유지나 동물성 재료를,\n",
      " 섣불리 더하지 않고,\n",
      " 맛의 차원을 끌어올렸나!,\n",
      " 유키히라 군은 이전에,\n",
      " 계란으로 커다란 실패를 겪었지,\n",
      " 합숙에서 불합격,\n",
      " 위기에 빠트린 오믈렛,\n",
      " 아버지와의 대결에서 완패한 리소토,\n",
      " 그 둘을 합쳐서 승부를 걸다니,\n",
      " 아버지?,\n",
      " 온갖 실패도,\n",
      " 490에 이르는 패배도,\n",
      " 그는 하나도 헛되이 하지 않았구나,\n",
      " 그렇게 말하면 듣기는 좋지만,\n",
      " 집념이 강하다고 볼 수 있지,\n",
      " 실패를 그대로 놔둘 생각이 없다,\n",
      " 유키히라 녀석,\n",
      " 천연덕스러운 얼굴이지만,\n",
      " 궁극의 오기 덩어리군,\n",
      " 그래도 실패했다는 경험은 얻었지,\n",
      " 그런 건 오기에 지나지 않아,\n",
      " 요리사에게 실패는,\n",
      " 용납되지 않으니까,\n",
      " 본격적으로 묵직한 감칠맛,\n",
      " 그럼에도 놀라우리만치,\n",
      " 뒷맛이 깔끔해!,\n",
      " 이것도 차트니의 효과인가!,\n",
      " 하지만 풍부한 향은,\n",
      " 하야마 군이 한 수 위네,\n",
      " 아니, 하지만,\n",
      " 쌀과 소스가 어우러질 때의,\n",
      " 중후함은 정말 훌륭해요!,\n",
      " 하야마 군의 카레가,\n",
      " 홀리바질을 주축으로 삼은,\n",
      " 끝이 예리한 창이라면,\n",
      " 이 카레는 파상공격,\n",
      " 맛의 콤비네이션 연타!,\n",
      " 둘 다 각자의 무기, 스타일을,\n",
      " 전력으로 주고받고 있어!,\n",
      " 이게 토오츠키의 정점을,\n",
      " 지향하는 자들의 싸움인가!,\n",
      " 어이, 어이,\n",
      " 극찬이잖아,\n",
      " 편입생 녀석,\n",
      " 설마 하야마 아키라를?!,\n",
      " 그럼 심사위원 여러분,\n",
      " 채점을 부탁드립니다,\n",
      " 18,\n",
      " 19,\n",
      " 18,\n",
      " 19,\n",
      " 19!,\n",
      " 합계는…!,\n",
      " 93점!,\n",
      " 유키히라 선수 93점!,\n",
      " 2위에 랭크인했습니다,\n",
      " 아앗, 아까워!,\n",
      " 1점 차이?,\n",
      " 93점…,\n",
      " 유키히라…,\n",
      " 2위인가,\n",
      " 동점,\n",
      " 유키히라 소마,\n",
      " 뭐, 역시 저 편입생이,\n",
      " 1위를 차지하진 못했나,\n",
      " 하야마는 카레의 화신 같은 놈이니까,\n",
      " 저 점수,\n",
      " 5명 중에서 3명은,\n",
      " 하야마보다 유키히라에게,\n",
      " 높은 점수를 줬어,\n",
      " 3:2라는 건,\n",
      " 혹시 이것이 식극 룰이었다면,\n",
      " 자네들,\n",
      " 그 예술품 같은 카레의,\n",
      " 대단함을 모르겠나!,\n",
      " 홀리바질을 제대로 살린 기교를!,\n",
      " 하지만 어디까지나 주제는 카레 요리,\n",
      " 스파이스만을 선택하는,\n",
      " 심사가 아니잖소?,\n",
      " 한 접시의 만족감이 포인트고…,\n",
      " 하야마 군의 카레는,\n",
      " 그 점도 훌륭했어!,\n",
      " 하지만 몇 번이고 계속 먹고,\n",
      " 싶었던 건 유키히라 선수의 요리고,\n",
      " 엑스트라는 입 다물어!,\n",
      " 감정에 좌우되다니!,\n",
      " 다각적인 시야를,\n",
      " 갖추지 못한 자에게,\n",
      " 미식을 논할 자격은 없어!,\n",
      " 아예 심사위원을 그만두지 그러나!,\n",
      " 뭐라고?!,\n",
      " 이놈이!,\n",
      " 그만하시고,\n",
      " 진정해주세요!,\n",
      " 이러니까 짝퉁 인텔리는 안 된다니까!,\n",
      " 입 다물어!,\n",
      " 어째 싸우는데?,\n",
      " 하야마가 1위, 맞지?,\n",
      " 아마도…,\n",
      " 일단은 당연히 살아남았다,\n",
      " 본선이 기대되는군,\n",
      " 유키히라 소마,\n",
      " 하야마 군, 하야마 군…,\n",
      " 본선에선 이기거나 지거나,\n",
      " 결과는 두 가지뿐,\n",
      " 만일 두 사람의,\n",
      " 직접 대결이 이루어진다면,\n",
      " 과연 누가 이길까,\n",
      " 제92기,\n",
      " 옥의 세대인가,\n",
      " 네, 지금부터,\n",
      " 가을 선발 예선,\n",
      " 그 종결을 기념해서,\n",
      " 축하 & 수고 파티를 개최합니다,\n",
      " 하나, 둘~,\n",
      " 건배~!,\n",
      " 메구미~,\n",
      " 메구미~~,\n",
      " 메구미~~!!,\n",
      " 대단했다, 메구미,\n",
      " 이대로 우승할 수 있을지도 모른당께,\n",
      " 뭐, 뭔 소리여,\n",
      " 타도코로 메구미,\n",
      " 호죠 양,\n",
      " 널 오해했던 것 같네,\n",
      " 본선 응원할게,\n",
      " 어?,\n",
      " 뭔가 곤란한 일이 생기면 내게 말해,\n",
      " 고마워, 호죠 양,\n",
      " 메구미는 대단한 애라고,\n",
      " 난 옛날에 알았는데,\n",
      " 유우키 짱,\n",
      " 선발 본선에서는,\n",
      " 내가 메구미의 응원단장이니까,\n",
      " 고마워,\n",
      " 어이, 메구미~,\n",
      " 같이 사진 찍자,\n",
      " 자, 얼른 가,\n",
      " 저기 부른다,\n",
      " 응,\n",
      " 유우키,\n",
      " 후미오 씨~,\n",
      " 응원 정말 고마웠어~,\n",
      " 앞으로 바빠지겠다,\n",
      " 메구미의 플랜카드도 준비해야지,\n",
      " 후미오 씨도 도와줘~,\n",
      " 오늘 밤은 네가,\n",
      " 좋아하는 거 만들어주마,\n",
      " 멋진 요리였어,\n",
      " 열심히 했구나,\n",
      " 엄청 질 좋은 오리고기잖아,\n",
      " 과연 대단하네,\n",
      " 보기만 해도 알아보다니,\n",
      " 누룩에는 그런 작용도 있구나,\n",
      " 흥미롭네,\n",
      " 속이 깊지?,\n",
      " 하지만 마루이에게 응원단이 있었다니,\n",
      " 그래,\n",
      " 마루이를 보는 눈이 달라졌다고,\n",
      " 하지만 당연하다는 듯,\n",
      " 내 방에서 연회구나,\n",
      " 너희도 많이 먹으렴,\n",
      " 아, 네…,\n",
      " 불러주셔서 감사합니다,\n",
      " 잇시키 선배,\n",
      " 알몸 앞치마 남이 어슬렁대는데,\n",
      " 왜 누구도 아무 말 않지?!,\n",
      " 그러고 보니 이부사키 군은?,\n",
      " 응?,\n",
      " 그렇다면 방에 틀어박혔구나!,\n",
      " 그 녀석, 얼굴에 드러내지 않았지만,\n",
      " 엄청 분한 것 같았으니까,\n",
      " 어쩔 수가 없네,\n",
      " 아예 끌고 와버릴까~,\n",
      " 본선 토너먼트는 2주 후,\n",
      " 이건 나키리 에리나를 제외한,\n",
      " 현시점의 토오츠키 1학년,\n",
      " 최강 결정전이야,\n",
      " 명심해라, 유키히라,\n",
      " 나와 겨루기 전에 진다면,\n",
      " 가만 안 둔다?,\n",
      " 오오, 좋아,\n",
      " 덤벼봐,\n",
      " 어이, 준,\n",
      " 혼자 술에 취해 잠들다니,\n",
      " 평소보다 더 문제 있잖아,\n",
      " 할 수 없네,\n",
      " 하야마 구운~,\n",
      " 세상을 바꿀지도~,\n",
      " 준,\n",
      " 난 본선에서도 이기고 말겠어,\n",
      " 날 찾아낸,\n",
      " 준을 위해서!,\n",
      " 뭐야!,\n",
      " 에리나도 참!,\n",
      " 오늘 밤 정도는 놀아줘도 되잖아,\n",
      " 네 사촌이 최고 득점으로,\n",
      " 예선을 통과했다고!,\n",
      " 축하하는 게 의무잖아!,\n",
      " 료 군도 그렇게 생각하지?,\n",
      " 난 어느 쪽이든 뭐…,\n",
      " 나 참!,\n",
      " 료 군은 내 편을 들어줘야지!,\n",
      " 네에…,\n",
      " 죄송합니다,\n",
      " 오늘 밤은 아직,\n",
      " 서류 정리가 남아있거든,\n",
      " 축하는 다음에 하도록 할게,\n",
      " 알았어,\n",
      " 오늘 밤은 포기해줄게,\n",
      " 내일 또 오겠어,\n",
      " 가자, 료 군,\n",
      " 네,\n",
      " 예선 통과 축하해,\n",
      " 아리스,\n",
      " 쿠로키바 군도,\n",
      " 네,\n",
      " 죄송합니다,\n",
      " 에리나 님은 바쁘시다고 했는데…,\n",
      " 어쩔 수 없지,\n",
      " 아리스니까,\n",
      " 히사코,\n",
      " 너도 축하해,\n",
      " 예선 통과는 당연하지만,\n",
      " 기쁘네,\n",
      " 본선에서도 힘을 다해줘,\n",
      " 네!,\n",
      " 제 기술을 더욱 갈고 닦아,\n",
      " 반드시 우승하겠습니다!,\n",
      " 히사코 언니~,\n",
      " 그 요리에서 풍긴 향기,\n",
      " 향기…,\n",
      " 향기…!,\n",
      " 오지 마!,\n",
      " 오지 마~!,\n",
      " 맛없다고오오오!,\n",
      " 유키히라 소마,\n",
      " 깨달았어,\n",
      " 예컨대, 너와 만나면 간단히,\n",
      " 세계는 뒤집히겠지,\n",
      " 소마 군,\n",
      " 타도코로, 어쩐 일이야?,\n",
      " 그게…,\n",
      " 왠지 소마 군 상태가 이상해서,\n",
      " 그랬나?,\n",
      " 그보다 타도코로,\n",
      " 카레에 고향 식자재를,\n",
      " 살린 모양이잖아?,\n",
      " 으, 으응,\n",
      " 제법이잖아,\n",
      " 그래도 왠지 실감이 안 나서,\n",
      " 반년 전까지는 퇴학 직전이었는데,\n",
      " 아아,\n",
      " 첫 수업 그립네,\n",
      " 둘이서 처음 파트너가 됐었지?,\n",
      " 전부 소마 군 덕분이야,\n",
      " 소마 군이 있어줬으니까,\n",
      " 난, 여기까지 올 수 있었어,\n",
      " 아니, 아니,\n",
      " 애초에 훌륭한 걸 가지고 있었잖아,\n",
      " 타도코로의 요리, 참 좋지?,\n",
      " 마음이 따뜻해진달까?,\n",
      " 난 좋아해,\n",
      " 고, 고마워,\n",
      " 정말 기뻐,\n",
      " 저 녀석들 둘이서 무슨 얘기지?,\n",
      " 근데 왜 내가 숨어서 몰래…,\n",
      " 어라라?,\n",
      " 왠지 분위기가 좋군요,\n",
      " [어느새…],\n",
      " 소마 군이야말로 정말 대단했어,\n",
      " 카레의 스페셜리스트인,\n",
      " 하야마 군과 호각으로 겨루고,\n",
      " 그래도 1점 차이가 나버렸어,\n",
      " 진짜로 이기려 들었는데,\n",
      " 마음만은 5명 전원에게,\n",
      " 만점을 받을 생각이었는데,\n",
      " 그, 그렇구나,\n",
      " 하야마는 내가 알지도 못한,\n",
      " 스파이스를 구사해서,\n",
      " 엄청난 요리를 만들어버렸어,\n",
      " 나도 더욱 넓은 세상을 보고 싶어,\n",
      " 다양한 식자재라든가 조리법이라든가,\n",
      " 현장을 접하고 무기를 늘려서,\n",
      " 그 모든 걸 앞으로 만들,\n",
      " 요리에 쏟아부겠어,\n",
      " 더욱 강해지고 싶어,\n",
      " 어이, 제2라운드 개시다!,\n",
      " 아직 밤은 지금부터 시작이야!,\n",
      " 나왔다,\n",
      " 잇시키 선배의 서드 폼!,\n",
      " 경영 수영복이다!,\n",
      " 마셔라, 마셔,\n",
      " 이부사키!,\n",
      " 쌀 주스~,\n",
      " 숨이 다 막히네,\n",
      " 유키히라!,\n",
      " 난 기필코 널 쓰러트리겠어!,\n",
      " 왠지 이상한 스위치가 들어갔는데,\n",
      " 저렇게 헛돌 때는,\n",
      " 내버려둬도 괜찮아,\n",
      " 과연 가족!,\n",
      " 가차 없어!,\n",
      " 엄청 고급 고기,\n",
      " 후미오 씨가 힘 좀 썼네,\n",
      " 잘 먹겠어!,\n",
      " 기다려!,\n",
      " 그 고기에 소스 같은 걸 뿌리면,\n",
      " 섬세한 감칠맛이 죽잖아!,\n",
      " 이 자식, 고기 얕보는 거냐!,\n",
      " 죄죄, 죄송합니다, 니쿠미 양!,\n",
      " 니쿠미라고 부르지 마!,\n",
      " 날 니쿠미라고 불러도 되는 건,\n",
      " 아니, 무슨 말을 하게 하는 거냐!,\n",
      " 이 자식!,\n",
      " 기운 나게 나도 뭐 하나 만들까,\n",
      " 저건 괴작에 도전하는 눈빛!,\n",
      " 유키히라는 얌전히 있어!,\n",
      " 소마 군은 안 만들어도 된당께,\n",
      " 아니, 실은 이미 만들었거든,\n",
      " 잡숴봐,\n",
      " 오징어 요구르트 곁들임,\n",
      " 이제 싫어어어어어엇!,\n",
      " 변변찮았습니다]\n"
     ]
    }
   ],
   "source": [
    "pprint(pre_chat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_training_data_by_disintegration(sentence):\n",
    "    disintegrated_sentence = konlpy.tag.Twitter().pos(sentence, norm=True, stem=True) \n",
    "    original_sentence = konlpy.tag.Twitter().pos(sentence) \n",
    "    inputData = []     \n",
    "    outputData = [] \n",
    "    is_asking = False \n",
    "    for w, t in disintegrated_sentence:\n",
    "        if w in name_dict:\n",
    "            w = 'NAME'    \n",
    "        if t not in ['Eomi', 'Josa', 'Number', 'KoreanParticle', 'Punctuation']:            \n",
    "            inputData.append(w) \n",
    "    for w, t in original_sentence: \n",
    "        if w in name_dict:\n",
    "            w = 'NAME'\n",
    "        if t not in ['Number', 'Punctuation']: \n",
    "            outputData.append(w) \n",
    "    if original_sentence[-1][1] == 'Punctuation' and original_sentence[-1][0] == \"?\": \n",
    "        if len(inputData) != 0 and len(outputData) != 0:            \n",
    "            is_asking = True # To extract ask-response raw data  \n",
    "    \n",
    "    return ' '.join(inputData), ' '.join(outputData), is_asking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_1 = []\n",
    "y_1 = []\n",
    "\n",
    "for sentence in pre_chat:\n",
    "    x,y,_ = get_training_data_by_disintegration(sentence)\n",
    "    x_1.append(x)\n",
    "    y_1.append(y)\n",
    "\n",
    "with codecs.open('data/training_x.txt', 'a', encoding='utf-8') as f:\n",
    "    for line in x_1:\n",
    "        f.write(line+'\\n')\n",
    "\n",
    "with codecs.open('data/training_y.txt', 'a', encoding='utf-8') as f:\n",
    "    for line in y_1:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "527"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputd, outputd, ask = get_training_data_by_disintegration(pre_chat[280])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 를 받다 못 요리\n"
     ]
    }
   ],
   "source": [
    "pprint(inputd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A 를 받지 못 한 요리 는\n"
     ]
    }
   ],
   "source": [
    "pprint(outputd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 상황1 : 일상대화\n",
    "* 상황2 : 레시피 관련 (식재료) 문의 (대체재료)\n",
    "* 상황3 : 레시피 추천\n",
    "* 상황4 : 칼로리 및 영양성분 문의\n",
    "* 상황5 : 기타"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"data/ingdict.txt\", 'rb')\n",
    "ingredient = pickle.load(f) # 식재료 사전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def disintegrate(sentence): \n",
    "    disintegrated_sentence = konlpy.tag.Twitter().pos(sentence, norm=True, stem=True)    \n",
    "    result = []\n",
    "    context_flag = 5\n",
    "    for w, t in disintegrated_sentence: \n",
    "        print w,t\n",
    "        if t == 'Noun':\n",
    "            if w in ingredient: context_flag = 2 # 상황2 레시피 관련...\n",
    "        \n",
    "        if t not in ['Eomi', 'Josa', 'Number', 'KoreanParticle', 'Punctuation']:            \n",
    "            result.append(w) \n",
    "    \n",
    "    return ' '.join(result), context_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 Determiner\n",
      "거 Noun\n",
      "말고 Josa\n",
      "카 Noun\n",
      "놀라다 Verb\n",
      "유 Noun\n",
      "쓰다 Verb\n",
      "안 VerbPrefix\n",
      "돼다 Verb\n",
      "? Punctuation\n"
     ]
    }
   ],
   "source": [
    "temp,context = disintegrate(\"이거 말고 카놀라유 쓰면 안돼?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이 거 루꼴 쓰다 안 돼다\n"
     ]
    }
   ],
   "source": [
    "pprint(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotion parser "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "긍/부정만 판별!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grammar model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = pd.DataFrame({'words' : x_1,\n",
    "            'labels' : y_1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_disintegrated_words = 1\n",
    "MAX_DOCUMENT_LENGTH = 10\n",
    "n_recovered_words = 5\n",
    "HIDDEN_SIZE = 10 \n",
    "EMBEDDING_SIZE = 25 \n",
    "\n",
    "def grammar_model(X, y): \n",
    "    word_vectors = learn.ops.categorical_variable(X, \n",
    "                                                  n_classes=n_disintegrated_words, \n",
    "                                                  embedding_size=EMBEDDING_SIZE, \n",
    "                                                  name='words') \n",
    "    in_X, in_y, out_y = learn.ops.seq2seq_inputs(word_vectors, y, MAX_DOCUMENT_LENGTH, MAX_DOCUMENT_LENGTH) \n",
    "    encoder_cell = tf.nn.rnn_cell.GRUCell(HIDDEN_SIZE) \n",
    "    decoder_cell = tf.nn.rnn_cell.OutputProjectionWrapper(tf.nn.rnn_cell.GRUCell(HIDDEN_SIZE), n_recovered_words)\n",
    "    decoding, _, sampling_decoding, _ = learn.ops.rnn_seq2seq(in_X, in_y, \n",
    "                                                              encoder_cell, decoder_cell=decoder_cell) \n",
    "    return learn.ops.sequence_classifier(decoding, out_y, sampling_decoding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Variable words/words_embeddings already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/ops/embeddings_ops.py\", line 84, in categorical_variable\n    [n_classes, embedding_size])\n  File \"<ipython-input-19-70fec03f28d8>\", line 11, in grammar_model\n    name='words')\n  File \"<ipython-input-20-ffe29a32e098>\", line 1, in <module>\n    grammar_model(x_1,y_1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-9d6487ffbd55>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrammar_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-19-70fec03f28d8>\u001b[0m in \u001b[0;36mgrammar_model\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m      9\u001b[0m                                                   \u001b[0mn_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_disintegrated_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m                                                   \u001b[0membedding_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mEMBEDDING_SIZE\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m                                                   name='words') \n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0min_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq2seq_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_vectors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_DOCUMENT_LENGTH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mMAX_DOCUMENT_LENGTH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mencoder_cell\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGRUCell\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHIDDEN_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/ops/embeddings_ops.pyc\u001b[0m in \u001b[0;36mcategorical_variable\u001b[1;34m(tensor_in, n_classes, embedding_size, name)\u001b[0m\n\u001b[0;32m     82\u001b[0m   \u001b[1;32mwith\u001b[0m \u001b[0mvs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     embeddings = vs.get_variable(name + \"_embeddings\",\n\u001b[1;32m---> 84\u001b[1;33m                                  [n_classes, embedding_size])\n\u001b[0m\u001b[0;32m     85\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0membedding_lookup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor_in\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[0;32m    871\u001b[0m       \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    872\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 873\u001b[1;33m       custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    874\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, var_store, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[0;32m    698\u001b[0m           \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    699\u001b[0m           \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidate_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 700\u001b[1;33m           custom_getter=custom_getter)\n\u001b[0m\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    702\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36mget_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, custom_getter)\u001b[0m\n\u001b[0;32m    215\u001b[0m           \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m           \u001b[0mcaching_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpartitioner\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m           validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m   def _get_partitioned_variable(\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_true_getter\u001b[1;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape)\u001b[0m\n\u001b[0;32m    200\u001b[0m           \u001b[0minitializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mregularizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreuse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreuse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m           \u001b[0mtrainable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcollections\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m           caching_device=caching_device, validate_shape=validate_shape)\n\u001b[0m\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcustom_getter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/variable_scope.pyc\u001b[0m in \u001b[0;36m_get_single_variable\u001b[1;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, validate_shape)\u001b[0m\n\u001b[0;32m    492\u001b[0m                          \u001b[1;34m\" Did you mean to set reuse=True in VarScope? \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    493\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[1;32m--> 494\u001b[1;33m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[0;32m    495\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    496\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Variable words/words_embeddings already exists, disallowed. Did you mean to set reuse=True in VarScope? Originally defined at:\n\n  File \"/usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/ops/embeddings_ops.py\", line 84, in categorical_variable\n    [n_classes, embedding_size])\n  File \"<ipython-input-19-70fec03f28d8>\", line 11, in grammar_model\n    name='words')\n  File \"<ipython-input-20-ffe29a32e098>\", line 1, in <module>\n    grammar_model(x_1,y_1)\n"
     ]
    }
   ],
   "source": [
    "grammar_model(X,y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tone generator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 3-layer sequence-to-sequence model\n",
    "* Almost same as grammar model(training set is different)\n",
    "<hr>\n",
    "\n",
    "* Input : sentence without tones\n",
    "* Output : sentence with tones\n",
    "* Data : Normal sentences from various conversation sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
